# mac-a-thon-transformers-workshop

A miniature implementation of the famous ["Attention Is All You Need" paper](https://arxiv.org/pdf/1706.03762)'s transformer architecture with layers/components built from scratch using PyTorch. This architecture is what started the snowball of high performance LLMs in the recent years, including the GPT models!
